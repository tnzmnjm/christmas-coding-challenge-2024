{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Selecting available GPUs on a multi-GPU machine\n",
    "\n",
    "If you wish to restrict the number of GPUs used for training on a multi-GPU machine, the simplest way is to use the `CUDA_VISIBLE_DEVICES` environment variable. To illustrate this, suppose your machine has multiple GPUs, and you only want to use one GPU—for example, the GPU with index 0. Instead of python some_script.py, you can run the following code from the terminal:"
   ],
   "id": "a8bfbbb5a888207f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "CUDA_VISIBLE_DEVICES=0 python some_script.py",
   "id": "d8dc04593814bf46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Or, if your machine has four GPUs and you only want to use the first and third GPU, you can use",
   "id": "7fa473301704bc7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "CUDA_VISIBLE_DEVICES=0, 2 python some_script.py",
   "id": "d9c71ad07963662e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Setting `CUDA_VISIBLE_DEVICES` in this way is a simple and effective way to manage GPU allocation without modifying your PyTorch scripts.\n",
    "Let’s now run this code and see how it works in practice by launching the code as a script from the terminal:"
   ],
   "id": "38af9d08d0916c8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "python ch02-DDP-script.py",
   "id": "f2f20b11a6f91936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note that it should work on both single and multi-GPU machines. If we run this code on a single GPU, we should see the following output:",
   "id": "ea8fbae7ff07989d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PyTorch version: 2.2.1+cu117\n",
    "CUDA available: True\n",
    "Number of GPUs available: 1\n",
    "[GPU0] Epoch: 001/003 | Batchsize 002 | Train/Val Loss: 0.62\n",
    "[GPU0] Epoch: 001/003 | Batchsize 002 | Train/Val Loss: 0.32\n",
    "[GPU0] Epoch: 002/003 | Batchsize 002 | Train/Val Loss: 0.11\n",
    "[GPU0] Epoch: 002/003 | Batchsize 002 | Train/Val Loss: 0.07\n",
    "[GPU0] Epoch: 003/003 | Batchsize 002 | Train/Val Loss: 0.02\n",
    "[GPU0] Epoch: 003/003 | Batchsize 002 | Train/Val Loss: 0.03\n",
    "[GPU0] Training accuracy 1.0\n",
    "[GPU0] Test accuracy 1.0"
   ],
   "id": "d741cbf00fa90b86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The code output looks similar to that using a single GPU (section A.9.2), which is a good sanity check.\n",
    "Now, if we run the same command and code on a machine with two GPUs, we should see the following:"
   ],
   "id": "dc3ab726210c35c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "PyTorch version: 2.2.1+cu117\n",
    "CUDA available: True\n",
    "Number of GPUs available: 2\n",
    "[GPU1] Epoch: 001/003 | Batchsize 002 | Train/Val Loss: 0.60\n",
    "[GPU0] Epoch: 001/003 | Batchsize 002 | Train/Val Loss: 0.59\n",
    "[GPU0] Epoch: 002/003 | Batchsize 002 | Train/Val Loss: 0.16\n",
    "[GPU1] Epoch: 002/003 | Batchsize 002 | Train/Val Loss: 0.17\n",
    "[GPU0] Epoch: 003/003 | Batchsize 002 | Train/Val Loss: 0.05\n",
    "[GPU1] Epoch: 003/003 | Batchsize 002 | Train/Val Loss: 0.05\n",
    "[GPU1] Training accuracy 1.0\n",
    "[GPU0] Training accuracy 1.0\n",
    "[GPU1] Test accuracy 1.0\n",
    "[GPU0] Test accuracy 1.0"
   ],
   "id": "30f134d54e374317"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As expected, we can see that some batches are processed on the first GPU `(GPU0)` and others on the second `(GPU1)`. However, we see duplicated output lines when printing the training and test accuracies. Each process (in other words, each GPU) prints the test accuracy independently. Since DDP replicates the model onto each GPU and each process runs independently, if you have a print statement inside your testing loop, each process will execute it, leading to repeated output lines. If this bothers you, you can fix it using the rank of each process to control your print statements:",
   "id": "4b49d64e36a88e24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if rank == 0:\n",
    "    print(\"Test accuracy: \", accuracy)"
   ],
   "id": "958f906aa882daf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This is, in a nutshell, how distributed training via DDP works. If you are interested in additional details, I recommend checking the official API documentation at https://mng.bz/9dPr.",
   "id": "4f453208a58ba7d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ALTERNATIVE PYTORCH APIS FOR MULTI-GPU TRAINING\n",
    "\n",
    "If you prefer a more straightforward way to use multiple GPUs in PyTorch, you can consider add-on APIs like the open-source `Fabric` library -->  (https://mng.bz/jXle)."
   ],
   "id": "c816a666b0287f84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summary\n",
    "- `PyTorch` is an open source library with three core components: a tensor library, automatic differentiation functions, and deep learning utilities.\n",
    "- PyTorch’s `tensor` library is similar to array libraries like `NumPy`.\n",
    "- In the context of PyTorch, tensors are array-like data structures representing scalars, vectors, matrices, and higher-dimensional arrays.\n",
    "- PyTorch tensors can be executed on the CPU, but one major advantage of PyTorch’s tensor format is its GPU support to accelerate computations.\n",
    "- The automatic differentiation (autograd) capabilities in PyTorch allow us to conveniently train neural networks using backpropagation without manually deriving gradients.\n",
    "- The deep learning utilities in PyTorch provide building blocks for creating custom deep neural networks.\n",
    "- PyTorch includes `Dataset` and `DataLoader` classes to set up efficient data-loading pipelines.\n",
    "- It’s easiest to train models on a CPU or single GPU.\n",
    "- Using `DistributedDataParallel` is the simplest way in PyTorch to accelerate the training if multiple GPUs are available."
   ],
   "id": "e67e8410b1fb1b44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be1506166c75122d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
